% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/process_tracks.R
\name{process_tracks}
\alias{process_tracks}
\title{Running compiled datasets through aniMotum's ssm}
\usage{
process_tracks(
  in_loc = "./compiled_raw_datasets/loc_all_raw_pre-qc.txt",
  out_dir = "./processed_datasets/",
  out_loc = "loc_ssm_6h",
  in_dive = "./compiled_raw_datasets/dive_all_raw_pre-qc.txt",
  out_dive = "loc_ssm_dive",
  in_ctd = "./compiled_raw_datasets/ctd_all_raw_pre-qc.txt",
  out_ctd = "loc_ssm_ctd",
  dep_date = NULL,
  append = TRUE,
  note_discards = TRUE,
  add_mpm = TRUE,
  mpm_model = "mpm",
  min_d = 5,
  tstep = 6,
  tstep_units = "hours",
  vmax = 4,
  max_tgap = 4,
  parallel = TRUE,
  chunk_prop = 0.1,
  return_output = FALSE
)
}
\arguments{
\item{in_loc}{file path for the compiled location dataset.}

\item{out_dir}{destination directory for outputs.}

\item{out_loc}{prefix for the output location file name.}

\item{in_dive}{file path for the compiled dive dataset.}

\item{out_dive}{prefix for the output dive file name.}

\item{in_ctd}{file path for the compiled ctd dataset.}

\item{out_ctd}{prefix for the output ctd file name.}

\item{dep_date}{Must be a 2-column data.frame with animal id and deployment date}

\item{append}{logical - would you like the dataset to be appended to a previously processed dataset, or processed from scratch?}

\item{note_discards}{logical - would you like a running tally of ids that have been discarded over the course of processing?}

\item{add_mpm}{logical - should a move persistence model be fitted in addition to the ssm?}

\item{mpm_model}{specify the move persistence model to use. Can be either c("mpm" or "jmpm"). See \link[aniMotum]{fit_mpm} for details}

\item{min_d}{minimum number of days of tracking data for a deployment to be processed}

\item{tstep}{specify the duration of the regular timestep to be fitted during the ssm}

\item{tstep_units}{specifiy the timestep units; it can be one of following c("hour", "hours", "min", "mins", "sec", "secs")}

\item{vmax}{the maximum speed in m/s that an individual can travel. This is used for the ssm speed filter.}

\item{max_tgap}{what is the maximum gap (in days) between location times before it should be flagged?}

\item{parallel}{logical - would you like processing to be run in parallel?}

\item{chunk_prop}{relative size of data chunks for splitting the dataset during processing. Value must be (0,1]}

\item{return_output}{logical - would you like the output to be returned? If FALSE, output will be written to disk only.}
}
\value{
a collection of csv and Rdata files with the ssm estimated locations (and move persistence values) for tracks at a regularised time interval, as well as for every dive and ctd profile. Also, a file noting, with reasons, all tracks that were removed during processing. If return_output = TRUE, a list of data.frames containing processed location, dive and ctd datasets will be returned
}
\description{
Running compiled datasets through aniMotum's ssm
}
